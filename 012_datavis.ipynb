{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digging Into Deep Time and Deep Cover\n",
    "\n",
    "<a href=\"https://doi.org/10.5281/zenodo.3875779\"><img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3875779.svg\" align=\"right\" alt=\"doi: 10.5281/zenodo.3875779\" style=\"padding: 0px 10px 10px 0px\"></a>\n",
    "<a href=\"https://github.com/morganjwilliams/gs2020-diggingdeeper/blob/master/LICENSE\"><img src=\"https://img.shields.io/badge/License-MIT-blue.svg\" align=\"right\" alt=\"License: MIT\" style=\"padding: 0px 10px 10px 0px\"></a>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<span id='authors'><b>Morgan Williams <a class=\"fa fa-twitter\" aria-hidden=\"true\" href=\"https://twitter.com/metasomite\" title=\"@metasomite\"></a></b>, Jens Klump, Steve Barnes and Fang Huang; </span>\n",
    "<span id='affiliation'><em>CSIRO Mineral Resources</em></span>\n",
    "\n",
    "\n",
    "### Contents\n",
    "\n",
    "| [**Abstract**](./00_overview.ipynb) | **Introduction**                                                    | [**Examples**](./00_overview.ipynb#Examples)            | [**Tools**](./00_overview.ipynb#Tools) | [**Insights**](./00_overview.ipynb#Insights) |\n",
    "|:-----|:-----|:-----|:-----|:-----|\n",
    "|  | [Minerals Exploration](./00_overview.ipynb#An-Evolving-Role-of-Geochemistry-in-Mineral-Exploration)  | [Classification](./011_classification.ipynb) |  |  |\n",
    "|  | [Data Driven Geochem](./00_overview.ipynb#Data-Driven-Geochemistry) | [Data Visualization](./012_datavis.ipynb) |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "While there are many avenues to improve the robustness of data analysis in research, there are also opportunities to expand how we explore our datasets, potentially allowing us to find 'latent' features faster, or provide additional perspectives and context.\n",
    "\n",
    "* Adding context to our data - what does it mean in the 'scheme of things'\n",
    "* Making the most of the dimensions we have, but acknowledging that we have limited ability to understand complex data - dimensional reduction, smart visualisations (e.g. distance vs area vs volume).\n",
    "\n",
    "**Key Messages**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualizing Uncertainty\n",
    "\n",
    "While some classification problems can be adapted to versions of binary classifications, most involve multiple classes. In the case of probabilistic classification, model outputs are typically a multidimensional array of multiclass probability estimates, where the relative uncertainty of classification is more difficult to ascertain, and harder again to visualize for a larger group of samples. One measure which is related to the uncertainty of classification is the [information entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)), which effectively measures the distribution of probability among a number of potential classes:\n",
    "\n",
    "\\\\[S = - \\sum{P_i \\cdot log(P_i)} \\\\]\n",
    "\n",
    "Where samples are predicted to belong to one of mutliple classes with high relative probability, entropy is low. Where a sample is predicted to belong to mutliple classes with more or less equal probability, entropy is high. This is a particularly useful measure for quick visualisations of classification outputs, where the entropy is rescaled to \\\\([0,1]\\\\) to give a relative opacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from pyrolite.util.skl.pipeline import SVC_pipeline\n",
    "from pyrolite.util.skl.vis import alphas_from_multiclass_prob\n",
    "from pyrolite.util.plot import DEFAULT_DISC_COLORMAP\n",
    "\n",
    "np.random.seed(82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = sklearn.datasets.load_wine()\n",
    "data, target = wine[\"data\"], wine[\"target\"]\n",
    "svc = SVC_pipeline(probability=True)\n",
    "gs = svc.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from pyrolite.util.plot.axes import share_axes\n",
    "fig, ax = plt.subplots(3, 4, figsize=(8,7))\n",
    "ax=ax.flat\n",
    "share_axes(ax[:-1], which='xy')\n",
    "\n",
    "cm = plt.cm.Greens\n",
    "\n",
    "ax[0].set_ylim(0, 1)\n",
    "n = 11\n",
    "dt = gs.predict_proba(data)[::12][:n]\n",
    "dtalpha = alphas_from_multiclass_prob(dt, method='entropy')\n",
    "for ix in range(n):\n",
    "    ax[ix].axhline(1/3, color='k', ls='--', lw=0.5)\n",
    "    ax[ix].bar(['A', 'B', 'C'], dt[ix], alpha=dtalpha[ix], facecolor='purple')\n",
    "    ax[ix].set_ylabel('Sample {}'.format(ix+1))\n",
    "    ax[ix].annotate(\"S: {:.2f}\".format(entropy(dt[ix]))+\"\\n\"+r\"$\\alpha$: {:.2f}\".format(dtalpha[ix]), \n",
    "                    xy=(0.95, 0.95), \n",
    "                    xycoords='axes fraction',\n",
    "                    ha='right', \n",
    "                    va='top')\n",
    "\n",
    "ax[-1].scatter([entropy(dt[ix]) for ix in range(n)], [dtalpha[ix]for ix in range(n)], color='k')\n",
    "ax[-1].set_xlabel('Entropy')\n",
    "ax[-1].set_ylabel('alpha')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "x, y = data[:, f0],data[:, f1],\n",
    "\n",
    "classes = gs.predict(data)\n",
    "c = DEFAULT_DISC_COLORMAP(classes)\n",
    "\n",
    "ax[0].scatter(x, y, c=c, s=50)\n",
    "\n",
    "c[:, -1] = alphas_from_multiclass_prob(gs.predict_proba(data), method='entropy')\n",
    "ax[1].scatter(x, y, c=c, s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying this to Geochemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pyrolite.comp\n",
    "import pyrolite.geochem\n",
    "from pyrolite.util.units import scale\n",
    "from pyrolite.util.skl.pipeline import SVC_pipeline\n",
    "from pyrolite.util.skl.vis import plot_mapping\n",
    "from pyrolite.util.plot import DEFAULT_DISC_COLORMAP\n",
    "from pyrolite.util.plot.legend import proxy_line\n",
    "\n",
    "df = pd.read_csv('https://storage.googleapis.com/aegc2019/ueki2018.csv')\n",
    "\n",
    "df_chem = df.pyrochem.oxides.join(\n",
    "    df.pyrochem.elements * scale('ppm', 'wt%')\n",
    ").pyrocomp.ILR().join(\n",
    "    df[[ 'Sr87Sr86', 'Nd143Nd144', 'Pb206Pb204', 'Pb207Pb204', 'Pb208Pb204']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {c: ix for ix, c in enumerate(df.Class.unique())}\n",
    "X, y = df_chem, df[\"Class\"]\n",
    "y = y.apply(lambda x: classes[x]) # turn these into integers for the colormap\n",
    "svc = SVC_pipeline(probability=True, scaler=StandardScaler(), kernel='rbf')\n",
    "gs = svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8, 4))\n",
    "\n",
    "xsample = X.sample(500)\n",
    "s=40\n",
    "\n",
    "a, tfm, mapped = plot_mapping(\n",
    "    xsample, \n",
    "    gs.best_estimator_, \n",
    "    ax=ax[1], \n",
    "    s=s,\n",
    "    init=\"pca\"\n",
    ")\n",
    "ax[0].scatter(*mapped.T, c=DEFAULT_DISC_COLORMAP(gs.predict(xsample)), s=s)\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "\n",
    "ax[1].legend([proxy_line(c=DEFAULT_DISC_COLORMAP(ix), ls='none', marker='o') for c, ix in classes.items()], \n",
    "             [c for c in classes.keys()], \n",
    "             bbox_to_anchor=(1.05, 1.0), \n",
    "             loc='upper left', \n",
    "             frameon=False, \n",
    "             fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional Reduction for Visualization\n",
    "\n",
    "UMAP Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique which can be used in a very similar way to other manifold methods within scikit-learn ([McInnes2018]), with the added flexibility of being able transform new/novel data. This is particularly useful for visualizing training and testing data together, but can also be applied to map reference compositions and boundaries into the projected space. UMAP can also be used for semi-supervised and supervised dimensional reduction and metric learning, but this is beyond the scope of these notebooks. The technique is based on a specific set of assumptions which may be violated in practice, but it remains effective for the uses described here.\n",
    "\n",
    "[McInnes2018]: https://doi.org/10.21105/joss.00861 \"McInnes, L., Healy, J., Saul, N., Grossberger, L., 2018. UMAP: uniform manifold approximation and projection. The Journal of Open Source Software 3, 861.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap  # required in case of umap install errors\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=100, min_dist=0.01)\n",
    "embedding = reducer.fit_transform(df_chem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(5,5))\n",
    "\n",
    "ax.scatter(*embedding.T, \n",
    "           c=DEFAULT_DISC_COLORMAP(gs.predict(df_chem)),\n",
    "           s=s)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax.legend([proxy_line(c=DEFAULT_DISC_COLORMAP(ix), ls='none', marker='o') for c, ix in classes.items()], \n",
    "          [c for c in classes.keys()],\n",
    "          bbox_to_anchor=(1.05, 1.0), \n",
    "          loc='upper left', \n",
    "          frameon=False, \n",
    "          fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change the number of components, for example to generate 3D figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeDreducer = umap.UMAP(n_components=3, n_neighbors=100, min_dist=0.01)\n",
    "threeDembedding = threeDreducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrolite.util.skl.vis import alphas_from_multiclass_prob\n",
    "\n",
    "c = DEFAULT_DISC_COLORMAP(gs.predict(X)) # predicted classes\n",
    "ps = gs.predict_proba(X) # probabilities\n",
    "c[:, -1] = alphas_from_multiclass_prob(ps, alpha=0.95) # append alphas to RGBA colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "\n",
    "fig = ipv.figure()\n",
    "fig = ipv.quickscatter(*threeDembedding.T,\n",
    "                 color=c,\n",
    "                 size=2, \n",
    "                 marker='sphere')\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Manifold Methods for Visualizing Covariate Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projecting new data into manifold space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Index\n",
    "\n",
    "| [**Abstract**](./00_overview.ipynb) | **Introduction**                                                    | [**Examples**](./00_overview.ipynb#Examples)            | [**Tools**](./00_overview.ipynb#Tools) | [**Insights**](./00_overview.ipynb#Insights) |\n",
    "|:-----|:-----|:-----|:-----|:-----|\n",
    "|  | [Minerals Exploration](./00_overview.ipynb#An-Evolving-Role-of-Geochemistry-in-Mineral-Exploration)  | [Classification](./011_classification.ipynb) |  |  |\n",
    "|  | [Data Driven Geochem](./00_overview.ipynb#Data-Driven-Geochemistry) | [Data Visualization](./012_datavis.ipynb) |  |  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
